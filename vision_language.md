# Vision Language


Paper: [Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision](https://arxiv.org/pdf/2102.05918.pdf)

**ALIGN**: **A** **L**arge-scale **I**ma**G**e & **N**oisy Text Embedding 
<span style="color:red">What</span>

1. Learning pre-trained representations for visions and vision language.



Paper: [Align before Fuse: Vision and Language Representation Learning with Momentum Distillation](https://browse.arxiv.org/pdf/2107.07651.pdf)

## 1. Introduction

1. Most existing methods for vision-language representation learning are based on the Transformer architecture for both vision and language encoders. Beacause the visual tokens (reigon-based image features) are not aligned with the textual tokens (word embeddings), it is 